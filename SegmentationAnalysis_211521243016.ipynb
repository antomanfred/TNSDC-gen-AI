{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6T6e63rN6BM",
        "outputId": "b1593b9f-b7ea-4cb9-a18e-14693c56702b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.0957 - accuracy: 0.6667 - val_loss: 1.1170 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 1.0738 - accuracy: 0.6667 - val_loss: 1.1196 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 1.0547 - accuracy: 0.6667 - val_loss: 1.1234 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.0372 - accuracy: 0.6667 - val_loss: 1.1304 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.0195 - accuracy: 0.6667 - val_loss: 1.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 1.0002 - accuracy: 0.6667 - val_loss: 1.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.9789 - accuracy: 0.6667 - val_loss: 1.1639 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.9553 - accuracy: 0.6667 - val_loss: 1.1833 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.9290 - accuracy: 0.6667 - val_loss: 1.2094 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.8995 - accuracy: 0.6667 - val_loss: 1.2452 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 1.5827 - accuracy: 0.0000e+00\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Manually create your dataset\n",
        "data = [\n",
        "    {\"post_text\": \"Great weather today!\", \"segment\": 0},  # Example posts with segment labels\n",
        "    {\"post_text\": \"I'm feeling happy\", \"segment\": 0},\n",
        "    {\"post_text\": \"It's raining outside\", \"segment\": 1},\n",
        "    {\"post_text\": \"New movie is releasing\", \"segment\": 1},\n",
        "    {\"post_text\": \"Politics is heating up\", \"segment\": 2},\n",
        "    {\"post_text\": \"Vote for change\", \"segment\": 2}\n",
        "]\n",
        "\n",
        "# Extract texts and labels\n",
        "texts = [entry['post_text'] for entry in data]\n",
        "labels = [entry['segment'] for entry in data]\n",
        "\n",
        "# Preprocessing\n",
        "max_words = 1000\n",
        "max_len = 20\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "X = padded_sequences\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the RNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(max_words, 64, input_length=max_len),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Number of segments is 3 in this case\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Manually create your dataset\n",
        "data = [\n",
        "    {\"post_text\": \"Great weather today!\", \"segment\": 0},  # Example posts with segment labels\n",
        "    {\"post_text\": \"I'm feeling happy\", \"segment\": 0},\n",
        "    {\"post_text\": \"It's raining outside\", \"segment\": 1},\n",
        "    {\"post_text\": \"New movie is releasing\", \"segment\": 1},\n",
        "    {\"post_text\": \"Politics is heating up\", \"segment\": 2},\n",
        "    {\"post_text\": \"Vote for change\", \"segment\": 2}\n",
        "]\n",
        "\n",
        "# Extract texts and labels\n",
        "texts = [entry['post_text'] for entry in data]\n",
        "labels = [entry['segment'] for entry in data]\n",
        "\n",
        "# Preprocessing\n",
        "max_words = 1000\n",
        "max_len = 20\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "X = padded_sequences\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameters to evaluate\n",
        "hyperparameters = [\n",
        "    {'embedding_dim': 32, 'lstm_units': 32},\n",
        "    {'embedding_dim': 64, 'lstm_units': 64},\n",
        "    {'embedding_dim': 128, 'lstm_units': 128}\n",
        "]\n",
        "\n",
        "for params in hyperparameters:\n",
        "    embedding_dim = params['embedding_dim']\n",
        "    lstm_units = params['lstm_units']\n",
        "\n",
        "    # Build the RNN model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(max_words, embedding_dim, input_length=max_len),\n",
        "        tf.keras.layers.LSTM(lstm_units),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(\"Test Accuracy (embedding_dim={}, lstm_units={}): {:.2f}%\".format(embedding_dim, lstm_units, accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Su20jPO-pt",
        "outputId": "93ee5d7c-94ff-4565-9b8e-b0aaa5c901c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.0944 - accuracy: 0.6667 - val_loss: 1.0999 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.0867 - accuracy: 0.6667 - val_loss: 1.0968 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.0794 - accuracy: 0.6667 - val_loss: 1.0935 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.0720 - accuracy: 0.6667 - val_loss: 1.0911 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 1.0644 - accuracy: 0.6667 - val_loss: 1.0899 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.0562 - accuracy: 0.6667 - val_loss: 1.0886 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0481 - accuracy: 0.6667 - val_loss: 1.0874 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.0392 - accuracy: 0.6667 - val_loss: 1.0867 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0296 - accuracy: 0.6667 - val_loss: 1.0864 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 1.0195 - accuracy: 0.6667 - val_loss: 1.0866 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.2596 - accuracy: 0.0000e+00\n",
            "Test Accuracy (embedding_dim=32, lstm_units=32): 0.00%\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.0916 - accuracy: 0.6667 - val_loss: 1.0939 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.0769 - accuracy: 0.6667 - val_loss: 1.0907 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.0641 - accuracy: 0.6667 - val_loss: 1.0888 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.0507 - accuracy: 0.6667 - val_loss: 1.0867 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0356 - accuracy: 0.6667 - val_loss: 1.0855 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.0182 - accuracy: 0.6667 - val_loss: 1.0858 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.9982 - accuracy: 0.6667 - val_loss: 1.0880 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.9754 - accuracy: 0.6667 - val_loss: 1.0927 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.9493 - accuracy: 0.6667 - val_loss: 1.1014 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.9195 - accuracy: 0.6667 - val_loss: 1.1154 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5631 - accuracy: 0.0000e+00\n",
            "Test Accuracy (embedding_dim=64, lstm_units=64): 0.00%\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.1098 - accuracy: 0.0000e+00 - val_loss: 1.1315 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 1.0786 - accuracy: 0.6667 - val_loss: 1.1235 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 1.0542 - accuracy: 0.6667 - val_loss: 1.1320 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 1.0241 - accuracy: 0.6667 - val_loss: 1.1483 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.9895 - accuracy: 0.6667 - val_loss: 1.1730 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.9481 - accuracy: 0.6667 - val_loss: 1.2119 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8991 - accuracy: 0.6667 - val_loss: 1.2729 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8447 - accuracy: 0.6667 - val_loss: 1.3714 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7896 - accuracy: 0.6667 - val_loss: 1.5437 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.7517 - accuracy: 0.6667 - val_loss: 1.7468 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1297 - accuracy: 0.0000e+00\n",
            "Test Accuracy (embedding_dim=128, lstm_units=128): 0.00%\n"
          ]
        }
      ]
    }
  ]
}